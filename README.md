# ğŸ§  AI Second Brain (Local RAG)

Personalny asystent oparty o architekturÄ™ **RAG (Retrieval-Augmented Generation)**, ktÃ³ry pozwala na interakcjÄ™ z prywatnymi dokumentami w trybie 100% offline.

## ğŸš€ Kluczowe Cechy
- **PeÅ‚na PrywatnoÅ›Ä‡:** DziÄ™ki wykorzystaniu lokalnych modeli, Å¼adne dane nie opuszczajÄ… Twojego komputera.
- **Hybrid Search:** Wykorzystanie bazy wektorowej Qdrant do szybkiego wyszukiwania kontekstowego.
- **Interfejs Streamlit:** Przejrzysty czat w przeglÄ…darce umoÅ¼liwiajÄ…cy wygodnÄ… pracÄ™ z bazÄ… wiedzy.

## ğŸ› ï¸ Stack Technologiczny
- **LLM:** Llama 3 (via Ollama)
- **Framework:** LlamaIndex
- **Baza Wektorowa:** Qdrant (uruchomiony w Dockerze)
- **Embedding Model:** BAAI/bge-small-en-v1.5
- **Frontend:** Streamlit

## âš™ï¸ Jak uruchomiÄ‡?

### 1. Wymagania
- Zainstalowany [Docker](https://www.docker.com/)
- Zainstalowana [Ollama](https://ollama.com/)

### 2. Konfiguracja bazy i modelu
```bash
# Uruchomienie bazy Qdrant
docker run -p 6333:6333 qdrant/qdrant

# Pobranie modelu Llama 3
ollama pull llama3

```
## ğŸ“º Demo
![AI Second Brain Demo](assets/demo.mp4)
